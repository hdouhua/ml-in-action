# RDD常用算子 第二波

[第一波 map、mapPartitions、flatMap 和 filter](./03.md) ，这四个算子都不会引入 Shuffle 操作。

在数据分析场景中，典型的计算类型分别是分组、聚合和排序，它们承担了数据分析场景中的大部分职责。
在 Spark 中使用 groupByKey、reduceByKey、aggregateByKey 和 sortByKey 这些算子来完成。*这些算子作用在 Paired RDD 之上*，所谓 Paired RDD，它指的是元素类型为（Key，Value）键值对的 RDD。它们*都会引入繁重的 Shuffle 计算*。

## groupByKey：分组收集

groupByKey 的字面意思是“按照 Key 做分组”，但实际上，groupByKey 算子包含两步，即分组和收集。具体来说，对于元素类型为（Key，Value）键值对的 Paired RDD，groupByKey 的功能就是对 Key 值相同的元素做分组，然后把相应的 Value 值，以集合的形式收集到一起。

```
groupByKey ： RDD[(Key, Value)] => RDD[(Key, Value 集合)]
```

以 WordCount 为例，上代码，

```scala
import org.apache.spark.rdd.RDD
 
// 以行为单位做分词
val cleanWordRDD: RDD[String] = _

// 把普通RDD映射为Paired RDD
val kvRDD: RDD[(String, String)] = cleanWordRDD.map(word => (word, word))
 
// 按照单词做分组收集
val words: RDD[(String, Iterable[String])] = kvRDD.groupByKey()
```

<img src="https://static001.geekbang.org/resource/image/6f/77/6f1c7fb6bebd3yy43b1404835fe86d77.jpg?wh=1920x1071" width="70%" />

从图上可以看出，为了完成分组收集，对于 Key 值相同、但分散在不同数据分区的原始数据记录，Spark 需要通过 Shuffle 操作，跨节点、跨进程地把它们分发到相同的数据分区。Shuffle 是资源密集型计算，对于动辄上百万、甚至上亿条数据记录的 RDD 来说，这样的 Shuffle 计算会产生大量的磁盘 I/O 与网络 I/O 开销，从而严重影响作业的执行性能。

尽管 groupByKey 的用法非常简单，但它的计算过程值得特别关注。从上图可以直观地感受到 *groupByKey 可能存在的性能隐患*。——全量原始数据在计算节点间传输

## reduceByKey：分组聚合

reduceByKey 的字面含义是“按照 Key 值做聚合”，它的计算逻辑，就是根据聚合函数 f 给出的算法，把 Key 值相同的多个元素，聚合成一个元素。

对于给定 RDD[(Key 类型，Value 类型)]，聚合函数 f 的类型，必须是（Value 类型，Value 类型） => （Value 类型）。
两个形参，且数值的类型必须与 Value 的类型相同，返回值也必须是 Value 类型的数值。

```
reduceByKey 聚合函数： (Value 类型，Value 类型) => (Value 类型)
```

上代码，

```scala
// 把RDD元素转换为（Key，Value）的形式
val kvRDD: RDD[(String, Int)] = cleanWordRDD.map(word => (word, 1))
 
// 按照单词做分组计数
val wordCounts: RDD[(String, Int)] = kvRDD.reduceByKey((x: Int, y: Int) => x + y)
```

<img src="https://static001.geekbang.org/resource/image/ac/85/aca17fe4d0fa5a52f4b9e73056aa1185.jpg?wh=1920x951" width="70%" />

上图中，在数据分区 0 的处理中，在 Map 阶段，reduceByKey 把 Key 同为 Streaming 的两条数据记录聚合为一条，聚合逻辑就是由函数 f 定义的、取两者之间 Value 较大的数据记录，这个过程称之为“Map 端聚合”。相应地，数据经由网络分发之后，在 Reduce 阶段完成的计算，我们称之为“Reduce 端聚合”。

有没有觉得 reduceByKey 与 map、filter 这些算子有一些相似的地方？给定处理函数 f，它们的用法都是“算子 (f)”。对于 map 来说，把 f 称作是*映射函数*，对 filter 来说，把 f 称作*判定函数*，而对于 reduceByKey，把 f 叫作*聚合函数*。

尽管 reduceByKey 也会引入 Shuffle，但相比 groupByKey 以全量原始数据记录的方式消耗磁盘与网络，reduceByKey 在落盘与分发之前，会先在 Shuffle 的 Map 阶段做初步的聚合计算。

对于大多数分组 & 聚合的计算需求来说，只要设计合适的聚合函数 f 都可以使用 reduceByKey 来实现计算逻辑。
reduceByKey 算子的局限性，在于其 *Map 阶段* 与 *Reduce 阶段*的*计算逻辑必须保持一致*，计算逻辑统一由聚合函数 f 定义。当计算场景需要在两个阶段执行不同计算逻辑的时候，reduceByKey 就爱莫能助了。—— aggregateByKey 登场

## aggregateByKey：灵活聚合算子

相比其他算子，aggregateByKey 算子的参数比较多。
需要提供一个初始值，一个 Map 端聚合函数 f1，以及一个 Reduce 端聚合函数 f2 。初始值可以是任意数值或是字符串；聚合函数都是带有两个形参和一个输出结果的普通函数。具体的调用形式如下所示：

>初始值似乎只是为了表明结果的数据类型  
>f1 作用于同一分区中的  
>f1 作用于各分区之间

```scala
val rdd: RDD[(Key类型，Value类型)] = _
rdd.aggregateByKey(初始值)(f1, f2)
```

这 3 个参数来说，需要注意的是它们之间的*类型需要保持一致*：
- 初始值类型，必须与 f2 的结果类型保持一致；
- f1 的形参类型，必须与 Paired RDD 的 Value 类型保持一致；
- f2 的形参类型，必须与 f1 的结果类型保持一致。

结合示意图来加深理解：

<img src="https://static001.geekbang.org/resource/image/b0/f7/b0a1c86590f4213fa0fc62f5dd4ca3f7.jpg?wh=1920x568" width="60%" />

举例，
在 WordCount 中，如果在 Map 阶段，以数据分区为单位，计算单词的加和；而在 Reduce 阶段，对于同样的单词，取加和最大的那个数值。

```scala
// 把RDD元素转换为（Key，Value）的形式
val kvRDD: RDD[(String, Int)] = cleanWordRDD.map(word => (word, 1))
 
// 显示定义Map阶段聚合函数f1
def f1(x: Int, y: Int): Int = {
    return x + y
}
 
// 显示定义Reduce阶段聚合函数f2
def f2(x: Int, y: Int): Int = {
    return math.max(x, y)
}
 
// 调用aggregateByKey，实现先加和、再求最大值
val wordCounts: RDD[(String, Int)] = kvRDD.aggregateByKey(0) (f1, f2)
```

<img src="https://static001.geekbang.org/resource/image/62/f3/62d25ab5df4fa53da4283263bb2128f3.jpg?wh=1920x1040" width="70%" />

与 reduceByKey 相比，aggregateByKey 的执行过程并没有什么两样，最主要的区别，还是 Map 端聚合与 Reduce 端聚合的计算逻辑是否一致。
与 reduceByKey 一样，aggregateByKey 也可以通过 Map 端的初步聚合来大幅削减数据量，在降低磁盘与网络开销的同时，提升 Shuffle 环节的执行性能。

## sortByKey：排序

sortByKey 这个算子，顾名思义，它的功能是“按照 Key 进行排序”。算子的用法比较简单，只需在 RDD 之上调用 sortByKey() 即可：

```scala
val rdd: RDD[(Key类型，Value类型)] = _
rdd.sortByKey()
```

在默认的情况下，sortByKey 按照 Key 值的升序（Ascending）对 RDD 进行排序，如果想按照降序（Descending）来排序的话，你需要给 sortByKey 传入 false。

## 练习

reduceByKey 和 aggregateByKey 它们二者之间的联系？可以使用 aggregateByKey 来实现 reduceByKey 的功能吗？

reduceByKey 和 aggregateByKey 的区别在于 reduceByKey 在 Map 端和 Reduce 时的聚合函数一致，而 aggregateByKey 在 Map 端 和 Reduce 端聚合函数可以不一致。可以认为 reduceByKey 是一种特殊的 aggregateByKey（ Map 和 Reduce 是同一个函数）。

可以使用 aggregateByKey 来实现 reduceByKey 的功能，即 aggregateByKey 传入的 Map 和 Reduce 是同一个函数。

reduceByKey 和 aggregateByKey 底层实现完全相同，都是 combineByKeyWithClassTag，只不过 reduceByKey 调用 combineByKeyWithClassTag 的入参 mergeValue 和 mergeCombiners 是相等的，aggregateByKey 是用户指定可以不等的，也就是说 reduceByKey 是一种特殊的 aggregateByKey。
