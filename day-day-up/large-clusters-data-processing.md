# 大规模数据处理

## 数据处理技术的三个阶段

超大规模数据处理的技术发展分为三个阶段：石器时代，青铜时代，蒸汽机时代。

沿着时间线看一下超大规模数据处理的重要技术以及它们产生的年代

![](https://static001.geekbang.org/resource/image/54/ca/54a0178e675d0054cda83b5dc89b1dca.png?wh=5000*3092 |width=50%)

- 石器时代

MapReduce 诞生之前的时期。

- 青铜时代

2003 年，MapReduce 的诞生标志了超大规模数据处理的第一次革命，而开创这段青铜时代的就是下面这篇论文《MapReduce: Simplified Data Processing on Large Clusters》。

> MapReduce 被硅谷一线公司淘汰的“致命伤”：高昂的维护成本和无法达到用户期待的时间性能

- 蒸汽机时代

到了 2014 年左右，Google 内部已经几乎没人写新的 MapReduce 了。

## 设计下一代数据处理技术？

有向无环图（DAG）能为多个步骤的数据处理依赖关系，建立很好的模型。

在一个复杂的数据处理系统中，难的不是开发系统，而是异常处理。

站在 2008 年春夏之交来设计下一代大规模数据处理框架，一个基本的模型会是图中这样子的：

![](https://static001.geekbang.org/resource/image/53/2e/53aa1aad08b11e6c2db5cf8bb584572e.png?wh=4909*3085 |width=50%)

后面的章节会给补充一些设计和使用大规模数据处理架构的基础知识。同时，也会深入剖析两个与这里的设计理念最接近的大数据处理框架，Apache Spark 和 Apache Beam。

## 实现大型电商热销榜？

规模增长的技术思维（mindset of scaling）——必备！

假设你的电商网站销售 10 亿件商品，已经跟踪了网站的销售记录：商品 id 和购买时间 {product_id, timestamp}，整个交易记录是 1000 亿行数据，TB 级。作为技术负责人，你会怎样设计一个系统，根据销售记录统计去年销量前 10 的商品呢？

![](https://static001.geekbang.org/resource/image/3e/af/3eaea261df4257f0cff4509d82f211af.png?wh=1992*638?wh=1992*638 |width=50%)

Top K 算法当数据规模变大会遇到哪些问题呢？

- 第一，内存占用。
- 第二，磁盘 I/O 等延时问题。

### 大规模分布式解决方案

在每一个计算集群，统计商品销量的集群，分别计算、统计。最后在单一机器就可以汇总结果了。

### 大规模数据处理框架的功能要求

如果这个世界一无所有，你会设计怎样的大规模数据处理框架？你要经常做一些思维实验，试试带领一下技术的发展，而不是永远跟随别人的技术方向。

两个最基本的需求是：

- 高度抽象的数据处理流程描述语言。能够用几行代码把业务逻辑描述清楚。
- 根据描述的数据处理流程，自动化的任务分配优化。

最理想情况下，作为用户我只想写两行代码：

第一行代码

```
sales_count = sale_records.Count()
```

第二行代码

```
top_k_sales = sales_count.TopK(k)
```

## 分布式系统的 SLA

SLA（Service-Level Agreement），也就是服务等级协议，指的是系统服务提供者（Provider）对客户（Customer）的一个服务承诺。这是衡量一个大型分布式系统是否“健康”的常见方法。

最常见的四个 SLA 指标，可用性、准确性、系统容量和延迟。

1. Availabilty

   可用性指的是系统服务能正常运行所占的时间百分比。

   服务中断（Service Outage）的时间：

   - 对于许多系统而言，4 个 9 的可用性（99.99％ Availability，或每年约 50 分钟的系统中断时间）即可以被认为是高可用性（High availability）。
   - 3 个 9 99.9% Availability 指的是一天当中系统服务将会有大约 86 秒的服务间断期。（ 24 × 60 × 60 × 0.001 = 86.4 秒）

2. Accuracy

   准确性指的是我们所设计的系统服务中，是否允许某些数据是不准确的或者是丢失了的。如果允许这样的情况发生，用户可以接受的概率（百分比）是多少？

   很多时候，系统架构会以错误率（Error Rate）来定义这一项 SLA。

   Error Rate = 可以用导致系统产生内部错误（Internal Error）的有效请求数，除以这期间的有效请求总数。

   硅谷一线公司所搭建的架构平台的准确性 SLA：

   - Google Cloud Platform 的 SLA 中，有着这样的准确性定义：每个月系统的错误率超过 5% 的时间要少于 0.1%，以每分钟为单位来计算。
   - 而亚马逊 AWS 云计算平台有着稍微不一样的准确性定义：以每 5 分钟为单位，错误率不会超过 0.1%。

   一般来说，我们可以采用性能测试（Performance Test）或者是查看系统日志（Log）两种方法来评估。

3. Capacity

   系统能够支持的预期负载量是多少，一般会以每秒的请求数为单位来表示。

   Twitter 发布的一项数据，Twitter 系统可以响应 30 万的 QPS 来读取 Twitter Timelines。这里 Twitter 系统给出的就是他们对于系统容量 （Capacity）的 SLA。

   怎么给自己设计的系统架构定义出准确的 QPS 呢？

   - 第一种，是使用限流（Throttling）的方式。

     假设我们在每台服务器都定义了一个每秒最多处理 1000 个请求的 RateLimiter，而我们有 N 台服务器，在最理想的情况下，我们的 QPS 可以达到 1000 \* N。

   - 第二种，是在系统交付前进行性能测试（Performance Test）。

     可以使用像 Apache JMeter 又或是 LoadRunner 这类型的工具对系统进行性能测试。这类工具可以测试出系统在峰值状态下可以应对的 QPS 是多少。

     这里的影响因素可能有命中缓存（Cache Hit）。此时，得到的 QPS 可能并不是真实的 QPS。

   - 第三种，是分析系统在实际使用时产生的日志（Log）。

     系统上线使用后，可以得到日志文件。一般的日志文件会记录每个时刻产生的请求，于是，可以通过系统每天在最繁忙时刻所接收到的请求数，来计算出系统可以承载的 QPS。

     不过，这种方法不一定可以得到系统可以承载的最大 QPS。

4. Latency

   系统在收到用户的请求到响应这个请求之间的时间间隔。
   
   在定义延迟的 SLA 时，常常看到系统的 SLA 会有 p95 或者是 p99 这样的延迟声明。这里的 p 指的是 percentile，也就是百分位的意思。如果说一个系统的 p95 延迟是 1 秒的话，那就表示在 100 个请求里面有 95 个请求的响应时间会少于 1 秒，而剩下的 5 个请求响应时间会大于 1 秒。

   为了降低系统的延迟，我们会将数据库中内容放进缓存（Cache）中，以此来减少数据库的读取时间。但总会有 5% 或者 1% 的用户抱怨产品的用户体验太差，因此在系统运行了一段时间后，得到了一些缓存命中率（Cache Hit Ratio）的信息后，需要通过优化系统来避免用户体验差。

### 小结

定义好一个系统架构的 SLA 对于一个优秀的架构师来说是必不可少的一项技能，也是一种基本素养。特别是当系统架构在不停迭代的时候，有了一个明确的 SLA，我们可以知道下一代系统架构的改进目标以及优化好的系统架构是否比上一代的系统 SLA 更加优秀。
