{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision\n",
    "\n",
    "Torchvision 是一个和 PyTorch 配合使用的 Python 包，包含很多图像处理的工具。\n",
    "\n",
    "流程：\n",
    "数据的读取、网络的设计、优化方法与损失函数的选择以及一些辅助的工具等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 的数据读取\n",
    "\n",
    "### DataSet 类\n",
    "\n",
    "无论使用自定义的数据集，还是官方封装好的数据集，其本质都是继承了 Dataset 类。而在继承 Dataset 类时，至少需要重写以下几个方法：\n",
    "- `__init__()`：构造函数，可自定义数据读取方法以及进行数据预处理；\n",
    "- `__len__()`：返回数据集大小；\n",
    "- `__getitem__()`：索引数据集中的某一个数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # 构造函数\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "\n",
    "    # 返回数据集大小\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "\n",
    "    # 返回索引的数据与标签\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在构造函数中，传入 Tensor 类型的数据与标签；在 `__len__` 函数中，直接返回 Tensor 的大小；在 `__getitem__` 函数中返回索引的数据与标签。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3045,  1.4716, -0.0198],\n",
      "        [ 0.1322,  0.8875,  0.0471],\n",
      "        [-0.7870,  0.4271, -0.3337],\n",
      "        [ 0.1074, -1.1179, -0.8699],\n",
      "        [-1.8975, -0.8072,  1.3093],\n",
      "        [-0.5782, -0.0682, -0.2453],\n",
      "        [-0.1306, -1.0480,  1.4519],\n",
      "        [-0.8955,  1.7510,  1.6876],\n",
      "        [-1.4361,  0.1746, -0.4942],\n",
      "        [-0.5906, -1.6072, -2.2137]])\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "Dataset size: 10\n",
      "tensor_data[0]:  (tensor([-1.3045,  1.4716, -0.0198]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "# 生成数据\n",
    "data_tensor = torch.randn(10, 3)\n",
    "target_tensor = torch.randint(2, (10,))\n",
    "\n",
    "print(data_tensor)\n",
    "print(target_tensor)\n",
    "\n",
    "# 将数据封装成Dataset\n",
    "my_dataset = MyDataset(data_tensor, target_tensor)\n",
    "\n",
    "print('Dataset size:', len(my_dataset))\n",
    "print('tensor_data[0]: ', my_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 类\n",
    "\n",
    "在实际项目中，如果数据量很大，考虑到内存有限、I/O 速度等问题，在训练过程中不可能一次性的将所有数据全部加载到内存中，也不能只用一个进程去加载，所以就需要多进程、迭代加载，而 DataLoader 就是基于这些需要被设计出来的。DataLoader 是一个迭代器，最基本的使用方法就是传入一个 Dataset 对象，它会根据参数 batch_size 的值生成一个 batch 的数据，节省内存的同时，它还可以实现多进程、数据打乱等处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4361,  0.1746, -0.4942],\n",
      "        [ 0.1074, -1.1179, -0.8699]]) tensor([0, 0])\n",
      "tensor([[ 0.1322,  0.8875,  0.0471],\n",
      "        [-0.5906, -1.6072, -2.2137]]) tensor([0, 1])\n",
      "tensor([[-1.3045,  1.4716, -0.0198],\n",
      "        [-0.1306, -1.0480,  1.4519]]) tensor([1, 0])\n",
      "tensor([[-0.7870,  0.4271, -0.3337],\n",
      "        [-1.8975, -0.8072,  1.3093]]) tensor([1, 0])\n",
      "tensor([[-0.5782, -0.0682, -0.2453],\n",
      "        [-0.8955,  1.7510,  1.6876]]) tensor([1, 0])\n",
      "One batch tensor data:  [tensor([[-1.4361,  0.1746, -0.4942],\n",
      "        [ 0.1074, -1.1179, -0.8699]]), tensor([0, 0])]\n"
     ]
    }
   ],
   "source": [
    "tensor_dataloader = DataLoader(dataset=my_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "for data, target in tensor_dataloader:\n",
    "    print(data, target)\n",
    "\n",
    "print('One batch tensor data: ', iter(tensor_dataloader).next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset：Dataset 类型，输入的数据集，必须参数；\n",
    "- batch_size：int 类型，每个 batch 有多少个样本；\n",
    "- shuffle：bool 类型，在每个 epoch 开始的时候，是否对数据进行重新打乱；\n",
    "- num_workers：int 类型，加载数据的进程数，0 意味着所有的数据都会被加载进主进程，默认为 0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTroch 官方提供了一些常用的图片数据集 —— Torchvision 。\n",
    "它是一个和 PyTorch 配合使用的 Python 包，集合了常用数据集 + 常见网络模型 + 常用图像处理方法。\n",
    "\n",
    "[torchvision.datasets包所有支持的数据集](https://pytorch.org/vision/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 数据集\n",
    "\n",
    "MNIST 数据集是一个著名的手写数字数据集，上手简单，在深度学习领域，手写数字识别是一个很经典的学习入门样例。\n",
    "\n",
    "[数据集下载](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "| 数据集 | 描述 | 字节数 |\n",
    "|---|---|---|\n",
    "| train-images-idx3-ubyte.gz | training set images | 9912422 bytes |\n",
    "| train-labels-idx1-ubyte.gz | training set labels | 28881 bytes |\n",
    "| t10k-images-idx3-ubyte.gz | test set images | 1648877 bytes |\n",
    "| t10k-labels-idx1-ubyte.gz | test set labels | 4542 bytes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./ds\n",
       "    Split: Train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先去手动解压 ds/MNIST/raw 下的文件，或者直接改 download=True\n",
    "mnist_dataset = torchvision.datasets.MNIST(root='./ds',\n",
    "                                           train=True,\n",
    "                                           transform=None,\n",
    "                                           target_transform=None,\n",
    "                                           download=False)\n",
    "\n",
    "mnist_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision.datasets.MNIST是一个类，对它进行实例化，即可返回一个 MNIST 数据集对象。构造函数包括包含 5 个参数：\n",
    "- root：是一个字符串，用于指定你想要保存 MNIST 数据集的位置。如果 download 是 Flase，则会从目标位置读取数据集；\n",
    "- download：是布尔类型，表示是否下载数据集。如果为 True，则会自动从网上下载这个数据集，存储到 root 指定的位置。如果指定位置已经存在数据集文件，则不会重复下载；\n",
    "- train：是布尔类型，表示是否加载训练集数据。如果为 True，则只加载训练数据。如果为 False，则只加载测试数据集。这里需要注意，并不是所有的数据集都做了训练集和测试集的划分，这个参数并不一定是有效参数，具体需要参考官方接口说明文档；\n",
    "- transform：用于对图像进行预处理操作，例如数据增强、归一化、旋转或缩放等。这些操作我们会在下节课展开讲解；\n",
    "- target_transform：用于对图像标签进行预处理操作。\n",
    "\n",
    "没有官方接口的图像数据集，也可以使用以 torchvision.datasets.ImageFolder 接口来自行定义。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x7F9BD164CE50>, 5)\n",
      "<class 'tuple'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset_list = list(mnist_dataset)\n",
    "item = mnist_dataset_list[0]\n",
    "print(item)\n",
    "print(type(item))\n",
    "print(len(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到上面的图像数据是 `PIL.Image.Image` 类型的，这种类型可以直接在 Jupyter 中显示出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label is: 5\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(item[0])\n",
    "print(\"Image label is:\", item[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('neuro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "757db7ef77c83814adbeeb3ac793403c6c9d7e2b87df671eda65f632ba05d1a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
