{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练的可视化监控\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorboardX\n",
    "\n",
    "Tensorboard 是 TensorFlow 中最常使用的可视化工具非，TensorboardX 使得 PyTorch 也享受到 Tensorboard 的便捷功能。\n",
    "\n",
    "### 安装\n",
    "\n",
    "安装 Tensorboard\n",
    "\n",
    "```shell\n",
    "pip install tensorboard\n",
    "# or\n",
    "conda install -c conda-forge --name mlab tensorboard\n",
    "```\n",
    "\n",
    "安装 TensorboardX\n",
    "\n",
    "```shell\n",
    "pip install tensorboardX\n",
    "```\n",
    "\n",
    "**PyTorch 1.8 之后的版本自带 TensorboardX，它被放在torch.utils.tensorboard中，因此无需多余配置。*\n",
    "\n",
    "\n",
    "### 使用\n",
    "\n",
    "为了使用 TensorboardX，我们首先需要创建一个 `SummaryWriter` 的实例，然后再使用`add_scalar`或`add_image`方法，将数字或图片记录到 SummaryWriter 实例中。\n",
    "\n",
    "```\n",
    "torch.utils.tensorboard.writer.SummaryWriter(log_dir=None)\n",
    "\n",
    "add_scalar(tag, scalar_value, global_step=None, walltime=None)\n",
    "```\n",
    "\n",
    "log_dir 表示保存日志的路径，默认会保存在“runs/ 当前时间 _ 主机名”文件夹中。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "# new ummaryWriter instance\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    # add_scalar ...\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n",
    "\n",
    "img = np.zeros((3, 100, 100))\n",
    "img[0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "\n",
    "# add_image\n",
    "writer.add_image('my_image', img, 0)\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行上面的代码后，会在当前目录下生成一个“runs”文件夹，里面存储了记录的数据。接着，只需要在当前目录下执行下面的命令，即可启动 Tensoboard。\n",
    "\n",
    "```shell\n",
    "tensorboard --logdir runs\n",
    "#---\n",
    "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
    "TensorBoard 2.12.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "浏览器中打开 <http://localhost:6006/> ，\n",
    "\n",
    "Tensorboard 中间区域就是上面 add_scalar 方法记录的 Loss 和 Accuracy。Tensorboard 已经按照迭代 step 绘制成了曲线图，可以非常直观地监控训练过程。\n",
    "\n",
    "在“IMAGES”的标签页中，可以显示刚刚用 add_image 方法记录的图像数据。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练过程的可视化\n",
    "\n",
    "模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 模型定义\n",
    "class LinearModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.weight = nn.Parameter(torch.randn(1))\n",
    "    self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "  def forward(self, input):\n",
    "    return (input * self.weight) + self.bias\n",
    "\n",
    "# 数据\n",
    "w = 2\n",
    "b = 3\n",
    "xlim = [-10, 10]\n",
    "x_train = np.random.randint(low=xlim[0], high=xlim[1], size=30)\n",
    "y_train = [w * x + b + random.randint(0,2) for x in x_train]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(500):\n",
    "    input = torch.from_numpy(x_train)\n",
    "    output = model(input)\n",
    "    loss = nn.MSELoss()(output, y_train)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar('Loss/train', loss, n_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这段代码，记录了训练过程中的 Loss 的变换过程。可以看出 Loss 是一个下降的趋势，说明随着训练过程，模型越来越拟合我们的训练数据了。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visdom\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5793f5fd016a7c9d61c898647250c8077897b034faffae3752cc53d107fe02e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
